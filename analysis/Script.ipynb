{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Now loading batch 1",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-939e455d9a51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Get Classification result of vgg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpect_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdnn_test_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPicloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvggid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Code\\venv\\dnnbrain\\dnnbrain\\dnn\\models.py\u001b[0m in \u001b[0;36mdnn_test_model\u001b[1;34m(dataloaders, model)\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Now loading batch {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mmodel_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs_label\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qu199\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Code\\venv\\dnnbrain\\dnnbrain\\dnn\\models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu1_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qu199\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qu199\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 338\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 4.00 GiB total capacity; 1.02 GiB already allocated; 0 bytes free; 383.48 MiB cached)"
     ],
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 4.00 GiB total capacity; 1.02 GiB already allocated; 0 bytes free; 383.48 MiB cached)",
     "output_type": "error"
    }
   ],
   "source": [
    "# 对训练的网络进行测试\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from dnnbrain.dnn.io import PicDataset, DataLoader\n",
    "from cnnface.dnn.vgg_identity_recons import Vgg_identity\n",
    "from dnnbrain.dnn.models import dnn_test_model\n",
    "\n",
    "# load noise image\n",
    "imgcsv_path =  'D:\\cnnface\\Emotion_analysis/happy_sad_test_400.csv'\n",
    "transform = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor()])\n",
    "PicSet = PicDataset(imgcsv_path, transform)\n",
    "Picloader = DataLoader(PicSet, batch_size=32,shuffle=False)\n",
    "# load model\n",
    "vggid = Vgg_identity()\n",
    "vggid.load_state_dict(torch.load('F:/Code/pretrained_model/vgg_emotion_CrossEntro.pth'))\n",
    "\n",
    "# Get Classification result of vgg\n",
    "label, expect_label, accuracy = dnn_test_model(Picloader, vggid)\n",
    "print(accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# extract dnn_activation\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from dnnbrain.dnn import analyzer\n",
    "from dnnbrain.dnn import io as dnn_io\n",
    "\n",
    "stim = 'D:\\cnnface\\Identity_analysis/identity2_train.csv'\n",
    "netloader = dnn_io.NetLoader('vggface')\n",
    "imgcropsize = netloader.img_size\n",
    "transform = transforms.Compose([transforms.Resize(imgcropsize),\n",
    "                                    transforms.ToTensor()])  \n",
    "picdataset = dnn_io.PicDataset(stim, transform=transform)\n",
    "picdataloader = DataLoader(picdataset, batch_size=8, shuffle=False)\n",
    "dnn_act = analyzer.dnn_activation(picdataloader, 'vggface', 'fc3')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "30",
      " ",
      "-20",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dnnbrain.dnn import io\n",
    "import os\n",
    "from PIL import Image \n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from cnnface.stimulus.Image_processing import average_img\n",
    "\n",
    "csv_file = 'D:\\cnnface\\Emotion_analysis/noiseface.csv'\n",
    "index_f = np.loadtxt('D:\\cnnface\\Emotion_analysis\\CI_analysis/label_happy.txt').astype('int64')\n",
    "index_m = np.loadtxt('D:\\cnnface\\Emotion_analysis\\CI_analysis/label_sad.txt').astype('int64')\n",
    "\n",
    "savepath_aver_f = 'D:\\cnnface\\Emotion_analysis\\CI_analysis\\ci/aver_happy_noise.jpg'\n",
    "savepath_aver_m = 'D:\\cnnface\\Emotion_analysis\\CI_analysis\\ci/aver_sad_noise.jpg'\n",
    "savepath_CI = 'D:\\cnnface\\Emotion_analysis\\CI_analysis\\ci/ci_noise.jpg'\n",
    "\n",
    "#Get pictures path from stim_csv and label txt.\n",
    "picset= io.PicDataset(csv_file)\n",
    "pre_picpath = picset.picpath\n",
    "sub_picpath = picset.picname\n",
    "\n",
    "f_picpath = [os.path.join(pre_picpath,sub_picpath[i]) for i in index_f]\n",
    "m_picpath = [os.path.join(pre_picpath,sub_picpath[i]) for i in index_m]\n",
    "\n",
    "#average all of the pictures as their label.\n",
    "aver_img_f = average_img(f_picpath)\n",
    "aver_img_m = average_img(m_picpath)\n",
    "\n",
    "#calculate the CI and superimpose image and subtract image.\n",
    "ci = aver_img_f.astype('int64') - aver_img_m.astype('int64')\n",
    "#ci = ci - ci.min()\n",
    "ci = ci * 5\n",
    "print(ci.max(),ci.min())\n",
    "\n",
    "# (Image.fromarray(aver_img_f.astype('uint8'))).save(savepath_aver_f,quality=95)\n",
    "# (Image.fromarray(aver_img_m.astype('uint8'))).save(savepath_aver_m,quality=95)\n",
    "# (Image.fromarray(ci.astype('uint8'))).save(savepath_CI,quality=95)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# savepath_CI = 'D:\\cnnface\\Emotion_analysis\\CI_analysis\\ci/ci_noise_nor.jpg'\n",
    "# nor = lambda x:(x-x.min())/(x.max() - x.min()) \n",
    "# ci  = nor(ci) * 255\n",
    "# (Image.fromarray(ci.astype('uint8'))).save(savepath_CI,quality=95)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "base_face = np.array(Image.open(r'D:\\cnnface\\Emotion_analysis\\face_template/baseface.jpg')).astype('int64')\n",
    "\n",
    "ci =  np.array(Image.open('D:\\cnnface\\Emotion_analysis\\CI_analysis\\ci/ci_noise.jpg')).astype('int64')\n",
    "\n",
    "bf_add = base_face + ci \n",
    "bf_sub = base_face - ci \n",
    "\n",
    "bf_add[bf_add>255] = 255\n",
    "bf_sub[bf_sub<0] = 0\n",
    "\n",
    "# nor = lambda x:(x-x.min())/(x.max() - x.min()) \n",
    "# bf_add_x = nor(bf_add) *255\n",
    "# bf_sub_x = nor(bf_sub) *255\n",
    "(Image.fromarray(bf_add.astype('uint8'))).save('D:\\cnnface\\Emotion_analysis\\CI_analysis\\ci/bf_add.jpg',quality=95)\n",
    "(Image.fromarray(bf_sub.astype('uint8'))).save('D:\\cnnface\\Emotion_analysis\\CI_analysis\\ci/bf_sub.jpg',quality=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "-20",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "usecols = list(range(513))\n",
    "usecols.remove(0)\n",
    "sinusoid = np.loadtxt('D:/cnnface/rcrci/sinusoid/cycle/sinuoid_4.csv',delimiter=',',skiprows=1,usecols=usecols)\n",
    "sinusoid = ((sinusoid - sinusoid.min())/(sinusoid.max() - sinusoid.min()))*255\n",
    "img_sinu = Image.fromarray(sinusoid)\n",
    "img_sinu.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from cnnface.stimulus import Image_processing\n",
    "\n",
    "CI_ori_p = 'D:/cnnface/female_male_test_51_addnoise\\Face_template/classification_noise/CI_ori.jpg'\n",
    "CI_ori_5 = 'D:/cnnface/female_male_test_51_addnoise\\Face_template/classification_noise/CI_ori_5.jpg'\n",
    "CI_ori_20 = 'D:/cnnface/female_male_test_51_addnoise\\Face_template/classification_noise/CI_ori_20.jpg'\n",
    "CI_sinusoid_nor = 'D:/cnnface/female_male_test_51_addnoise\\Face_template/classification_noise/CI_sinusoid_nor.jpg'\n",
    "CI_sinusoid5_nor = 'D:/cnnface/female_male_test_51_addnoise\\Face_template/classification_noise/CI_sinusoid5_nor.jpg'\n",
    "\n",
    "# Image_processing.image_freq_hist_plot(CI_ori_p)\n",
    "# Image_processing.image_freq_hist_plot(CI_ori_5)\n",
    "# Image_processing.image_freq_hist_plot(CI_ori_20)\n",
    "# Image_processing.image_freq_hist_plot(CI_sinusoid_nor)\n",
    "# Image_processing.image_freq_hist_plot(CI_sinusoid5_nor)\n",
    "\n",
    "\n",
    "Image_processing.img_zmap(CI_ori_p)\n",
    "Image_processing.img_zmap(CI_ori_5)\n",
    "Image_processing.img_zmap(CI_ori_20)\n",
    "Image_processing.img_zmap(CI_sinusoid_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pg\n",
    "\n",
    "CI_sinusoid_nor = 'D:/cnnface/female_male_test_51_addnoise\\Face_template/classification_noise/CI_sinusoid_nor.jpg'\n",
    "CI = Image.open(CI_sinusoid_nor)\n",
    "CI_arr = np.array(CI)\n",
    "\n",
    "ci_map = plt.imshow(CI_arr,cmap = 'jet',interpolation='nearest')\n",
    "save_path  ='D:/cnnface/female_male_test_51_addnoise/Face_template/classification_noise/CI_jet.jpg'\n",
    "pg.imsave(save_path,CI_arr,cmap = 'jet',format='jpg',dpi=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#read image path from csv.file\n",
    "csv_file = 'D:/cnnface/female_male_test_51_addnoise/rcicr_sinusoid_noise.csv'\n",
    "pd = pd.read_csv(csv_file,skiprows=1)\n",
    "stimID = np.array(pd['stimID'])\n",
    "with open(csv_file,'r') as f:\n",
    "    picpath = f.readline().rstrip()\n",
    "    \n",
    "#read base img \n",
    "base_img = Image.open('D:/cnnface/female_male_test_51_addnoise/Face_template/face_template/frame054_gray_512.jpg')\n",
    "baseimg_arr = np.array(base_img).astype('int32')\n",
    "img_min = []\n",
    "img_mean = []\n",
    "img_max = []\n",
    "\n",
    "#read image from array\n",
    "#calculate the min mean max of singal pictures\n",
    "for x,i in enumerate(stimID):\n",
    "    picimg = Image.open(os.path.join(picpath, i))\n",
    "    picimg_arr = np.array(picimg).astype('int32')\n",
    "    contrast = picimg_arr - baseimg_arr\n",
    "    # - base image to get the pixel (positive and negative)\n",
    "    con_min = contrast.min()\n",
    "    con_mean = contrast.mean()\n",
    "    con_max = contrast.max()\n",
    "    \n",
    "    if x <5:\n",
    "        plt.hist(contrast)\n",
    "        plt.show()\n",
    "    img_min.append(con_min)\n",
    "    img_mean.append(con_mean)\n",
    "    img_max.append(con_max)\n",
    "#sum and plot the hist of min ,mean,max of all pictures\n",
    "\n",
    "plt.hist(img_min)\n",
    "plt.show()\n",
    "plt.hist(img_mean)\n",
    "plt.show()\n",
    "plt.hist(img_max)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#load RData file to python\n",
    "import rpy2.robjects as robjects\n",
    "import numpy as np\n",
    "robjects.r['load'](\"D:/cnnface/female_male_test_51_addnoise/Face_template/meta_data/pythonRead/sinusoid1000_patches.RData\")\n",
    "\n",
    "x = robjects.r['patches']\n",
    "print(np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#convert .RData to npy file\n",
    "import rpy2.robjects as robjects\n",
    "import numpy as np\n",
    "\n",
    "robjects.r['load'](\"D:/cnnface/female_male_test_51_addnoise/Face_template/meta_data/rcic_seed_1_time_9月_18_2019_10_07.Rdata\")\n",
    "params = robjects.r['stimuli_params'][0]\n",
    "\n",
    "params_1000 = np.array(params)\n",
    "\n",
    "robjects.r['load'](\"D:/cnnface/female_male_test_51_addnoise/Face_template/meta_data/rcic_seed_1_time_9月_18_2019_10_30.Rdata\")\n",
    "params = robjects.r['stimuli_params'][0]\n",
    "\n",
    "params_2000 = np.array(params)\n",
    "\n",
    "robjects.r['load'](\"D:/cnnface/female_male_test_51_addnoise/Face_template/meta_data/rcic_seed_1_time_9月_18_2019_10_45.Rdata\")\n",
    "params = robjects.r['stimuli_params'][0]\n",
    "\n",
    "params_3000 = np.array(params)\n",
    "\n",
    "robjects.r['load'](\"D:/cnnface/female_male_test_51_addnoise/Face_template/meta_data/rcic_seed_1_time_9月_18_2019_11_02.Rdata\")\n",
    "params = robjects.r['stimuli_params'][0]\n",
    "\n",
    "params_4000 = np.array(params)\n",
    "\n",
    "robjects.r['load'](\"D:/cnnface/female_male_test_51_addnoise/Face_template/meta_data/rcic_seed_1_time_9月_18_2019_11_22.Rdata\")\n",
    "params = robjects.r['stimuli_params'][0]\n",
    "\n",
    "params_5000 = np.array(params)\n",
    "\n",
    "p = np.concatenate((params_1000,params_2000),axis=0)\n",
    "p = np.concatenate((p,params_3000),axis=0)\n",
    "p = np.concatenate((p,params_4000),axis=0)\n",
    "p = np.concatenate((p,params_5000),axis=0)\n",
    "\n",
    "np.save('D:/cnnface/female_male_test_51_addnoise/Face_template/meta_data/params_5000',p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#convert .RData to npy file\n",
    "import rpy2.robjects as robjects\n",
    "import numpy as np\n",
    "\n",
    "robjects.r['load'](\"D:/cnnface/female_male_test_51_addnoise/Face_template/meta_data/rcic_seed_1_time_9月_18_2019_10_07.Rdata\")\n",
    "p = robjects.r['p']\n",
    "print(p.names)\n",
    "patches = p[0]\n",
    "patchidx = p[1]\n",
    "\n",
    "patches = np.array(patches)\n",
    "patchidx = np.array(patchidx)\n",
    "\n",
    "np.save('D:/cnnface/female_male_test_51_addnoise/Face_template/meta_data/patches.npy',patches)\n",
    "np.save('D:/cnnface/female_male_test_51_addnoise/Face_template/meta_data/patchidx.npy',patchidx)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}